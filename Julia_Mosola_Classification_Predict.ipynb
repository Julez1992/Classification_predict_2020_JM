{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Advanced Classification Predict\n",
    "\n",
    "© Explore Data Science Academy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Honour Code\n",
    "\n",
    "I **JULIA MOSOLA**, confirm - by submitting this document - that the solutions in this notebook are a result of my own work and that I abide by the EDSA honour code (https://drive.google.com/file/d/1QDCjGZJ8-FmJE3bZdIQNwnJyQKPhHZBn/view?usp=sharing).\n",
    "\n",
    "Non-compliance with the honour code constitutes a material breach of contract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install imblearn --user\n",
    "#!pip install SpellChecker\n",
    "#!pip install pyspellchecker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Read In the Data\n",
    "\n",
    "Do not modify or remove any of the code in these cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\JMOSOLA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\JMOSOLA\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "from IPython.display import IFrame\n",
    "from IPython import display\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "import imblearn\n",
    "import csv\n",
    "%matplotlib inline\n",
    "\n",
    "from nltk import TreebankWordTokenizer, SnowballStemmer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import  word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk import SnowballStemmer, PorterStemmer, LancasterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn import feature_selection\n",
    "from sklearn.feature_selection import f_classif\n",
    "from sklearn import metrics\n",
    "from spellchecker import SpellChecker\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import string\n",
    "import urllib\n",
    "import math\n",
    "import re\n",
    "\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>PolySciMajor EPA chief doesn't think carbon di...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's not like we lack evidence of anthropogeni...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>RT @RawStory: Researchers say we have three ye...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#TodayinMaker# WIRED : 2016 was a pivotal year...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @SoyNovioDeTodas: It's 2016, and a racist, ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  PolySciMajor EPA chief doesn't think carbon di...   625221\n",
       "1          1  It's not like we lack evidence of anthropogeni...   126103\n",
       "2          2  RT @RawStory: Researchers say we have three ye...   698562\n",
       "3          1  #TodayinMaker# WIRED : 2016 was a pivotal year...   573736\n",
       "4          1  RT @SoyNovioDeTodas: It's 2016, and a racist, ...   466954"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train  = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test_with_no_labels.csv') # no labels\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 3)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Europe will now be looking to China to make su...</td>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Combine this with the polling of staffers re c...</td>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The scary, unimpeachable evidence that climate...</td>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>@Karoli @morgfair @OsborneInk @dailykos \\nPuti...</td>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @FakeWillMoore: 'Female orgasms cause globa...</td>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             message  tweetid\n",
       "0  Europe will now be looking to China to make su...   169760\n",
       "1  Combine this with the polling of staffers re c...    35326\n",
       "2  The scary, unimpeachable evidence that climate...   224985\n",
       "3  @Karoli @morgfair @OsborneInk @dailykos \\nPuti...   476263\n",
       "4  RT @FakeWillMoore: 'Female orgasms cause globa...   872928"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. https://t.co/gvWYaauU8R'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.message[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Refer to this diagram to guide you while you build your model. Some of the steps will be fleshed out in this template."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Overview](process_overview_final.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic preprocessing\n",
    "\n",
    "Here is a template you may use for your initial base model. \n",
    "\n",
    "### Removing URL's\n",
    "Write a function that removes URL's from a single tweet. \n",
    "\n",
    "**Function input:**\n",
    "- A single string object (tweet) \n",
    "\n",
    "**Function output:**\n",
    "- The tweet with URL's removed as a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def replace_urls(df):\n",
    "    pattern_url = r'http[s]?://(?:[A-Za-z]|[0-9]|[$-_@.&+]|[!*\\(\\),]|(?:%[0-9A-Fa-f][0-9A-Fa-f]))+'\n",
    "    subs_url = r'url-web'\n",
    "    df['message'] = df['message'].replace(to_replace = pattern_url, value = subs_url, regex = True)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @thenation: Mike Pence doesn’t believe in global warming or that smoking causes lung cancer. url-web'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean=replace_urls(train)\n",
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert to lowercase\n",
    "\n",
    "Write a function that converts a single tweet to lowercase.\n",
    "\n",
    "**Function input:**\n",
    "- A single string object (tweet) \n",
    "\n",
    "**Function output:**\n",
    "- The tweet in lowercase as a single object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_lowerd(text):\n",
    "    return text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @thenation: mike pence doesn’t believe in global warming or that smoking causes lung cancer. url-web'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['message']=df_clean['message'].apply(to_lowerd)\n",
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopword(text):\n",
    "    stop = stopwords.words('english')\n",
    "    return ' '.join([word for word in text.split() if word not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt @thenation: mike pence doesn’t believe global warming smoking causes lung cancer. url-web'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['message']=df_clean['message'].apply(remove_stopword)\n",
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide ma...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt @rawstory: researchers say three years act ...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>#todayinmaker# wired : 2016 pivotal year war c...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt @soynoviodetodas: 2016, racist, sexist, cli...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief think carbon dioxide ma...   625221\n",
       "1          1    like lack evidence anthropogenic global warming   126103\n",
       "2          2  rt @rawstory: researchers say three years act ...   698562\n",
       "3          1  #todayinmaker# wired : 2016 pivotal year war c...   573736\n",
       "4          1  rt @soynoviodetodas: 2016, racist, sexist, cli...   466954"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuations(text):\n",
    "    for punctuation in string.punctuation:\n",
    "        text = text.replace(punctuation, '')\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean[\"message\"]=df_clean[\"message\"].apply(remove_punctuations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'rt thenation mike pence doesn’t believe global warming smoking causes lung cancer urlweb'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide ma...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt rawstory researchers say three years act cl...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired  2016 pivotal year war clim...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  polyscimajor epa chief think carbon dioxide ma...   625221\n",
       "1          1    like lack evidence anthropogenic global warming   126103\n",
       "2          2  rt rawstory researchers say three years act cl...   698562\n",
       "3          1  todayinmaker wired  2016 pivotal year war clim...   573736\n",
       "4          1  rt soynoviodetodas 2016 racist sexist climate ...   466954"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>polyscimajor epa chief think carbon dioxide ma...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>like lack evidence anthropogenic global warming</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>rt rawstory researchers say three years act cl...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>todayinmaker wired  2016 pivotal year war clim...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>rt soynoviodetodas 2016 racist sexist climate ...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15814</th>\n",
       "      <td>1</td>\n",
       "      <td>rt ezlusztig took material global warming lgbt...</td>\n",
       "      <td>22001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15815</th>\n",
       "      <td>2</td>\n",
       "      <td>rt washingtonpost climate change could breakin...</td>\n",
       "      <td>17856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15816</th>\n",
       "      <td>0</td>\n",
       "      <td>notiven rt nytimesworld what trump actually be...</td>\n",
       "      <td>384248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15817</th>\n",
       "      <td>-1</td>\n",
       "      <td>rt sara8smiles hey liberals climate change cra...</td>\n",
       "      <td>819732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15818</th>\n",
       "      <td>0</td>\n",
       "      <td>rt chetcannon kurteichenwalds climate change e...</td>\n",
       "      <td>806319</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15819 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sentiment                                            message  tweetid\n",
       "0              1  polyscimajor epa chief think carbon dioxide ma...   625221\n",
       "1              1    like lack evidence anthropogenic global warming   126103\n",
       "2              2  rt rawstory researchers say three years act cl...   698562\n",
       "3              1  todayinmaker wired  2016 pivotal year war clim...   573736\n",
       "4              1  rt soynoviodetodas 2016 racist sexist climate ...   466954\n",
       "...          ...                                                ...      ...\n",
       "15814          1  rt ezlusztig took material global warming lgbt...    22001\n",
       "15815          2  rt washingtonpost climate change could breakin...    17856\n",
       "15816          0  notiven rt nytimesworld what trump actually be...   384248\n",
       "15817         -1  rt sara8smiles hey liberals climate change cra...   819732\n",
       "15818          0  rt chetcannon kurteichenwalds climate change e...   806319\n",
       "\n",
       "[15819 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "spell=SpellChecker()\n",
    "def spell_check(texts):\n",
    "    result=[]\n",
    "    incorrect_spelling=spell.unknown(texts.split())\n",
    "    for text in texts.split():\n",
    "        if text in incorrect_spelling:\n",
    "            result.append(spell.correction(text))\n",
    "        else:\n",
    "            result.append(text)\n",
    "    return \" \".join(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "df_clean[\"message\"]=df_clean[\"message\"].apply(spell_check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'todayinmaker wired  2016 pivotal year war climate change urlweb'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.message[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_tokenized(text):\n",
    "    tk = TweetTokenizer()\n",
    "    return tk.tokenize(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'thenation',\n",
       " 'mike',\n",
       " 'pence',\n",
       " 'doesn',\n",
       " '’',\n",
       " 't',\n",
       " 'believe',\n",
       " 'global',\n",
       " 'warming',\n",
       " 'smoking',\n",
       " 'causes',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'urlweb']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['message'] =df_clean['message'].apply(tt_tokenized)\n",
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemma(words):\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    return [lemmatizer.lemmatize(word) for word in words] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['cat', 'cactus', 'lover', 'loving', 'run', 'ran']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "lista=(\"cats\",\"cacti\",\"lovers\",\"loving\",\"run\",\"ran\")\n",
    "lemma(lista)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['rt',\n",
       " 'thenation',\n",
       " 'mike',\n",
       " 'penny',\n",
       " 'doesn',\n",
       " '’',\n",
       " 't',\n",
       " 'believe',\n",
       " 'global',\n",
       " 'warming',\n",
       " 'smoking',\n",
       " 'cause',\n",
       " 'lung',\n",
       " 'cancer',\n",
       " 'urlweb']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean['message']= df_clean['message'].apply(lemma)\n",
    "df_clean.message[6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentiment</th>\n",
       "      <th>message</th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>[polyscimajor, epa, chief, think, carbon, diox...</td>\n",
       "      <td>625221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[like, lack, evidence, anthropogenic, global, ...</td>\n",
       "      <td>126103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[rt, rawstory, researcher, say, three, year, a...</td>\n",
       "      <td>698562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>[todayinmaker, wired, 2016, pivotal, year, war...</td>\n",
       "      <td>573736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>[rt, soynoviodetodas, 2016, racist, sexist, cl...</td>\n",
       "      <td>466954</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sentiment                                            message  tweetid\n",
       "0          1  [polyscimajor, epa, chief, think, carbon, diox...   625221\n",
       "1          1  [like, lack, evidence, anthropogenic, global, ...   126103\n",
       "2          2  [rt, rawstory, researcher, say, three, year, a...   698562\n",
       "3          1  [todayinmaker, wired, 2016, pivotal, year, war...   573736\n",
       "4          1  [rt, soynoviodetodas, 2016, racist, sexist, cl...   466954"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 3)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [polyscimajor, epa, chief, think, carbon, diox...\n",
       "1    [like, lack, evidence, anthropogenic, global, ...\n",
       "2    [rt, rawstory, researcher, say, three, year, a...\n",
       "3    [todayinmaker, wired, 2016, pivotal, year, war...\n",
       "4    [rt, soynoviodetodas, 2016, racist, sexist, cl...\n",
       "Name: message, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_clean[\"message\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_senti=df_clean[['message','sentiment']].groupby('sentiment').count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>message</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>-1</th>\n",
       "      <td>1296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           message\n",
       "sentiment         \n",
       "-1            1296\n",
       " 0            2353\n",
       " 1            8530\n",
       " 2            3640"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_senti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum_senti.sort_values('message', ascending=False).plot(kind='bar')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorising \n",
    "\n",
    "Vectorise your cleaned data using the vectoriser you defined earlier. Don't forget to fit the vectoriser to the data you just cleaned. Store your vectorised data in `train_vec`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JMOSOLA\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:516: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "vecto=TfidfVectorizer(preprocessor=list,tokenizer=list,ngram_range=(1,2),max_features=10000,min_df=2,strip_accents=\"ascii\", smooth_idf=False)\n",
    "vecto.fit(df_clean['message'])\n",
    "X=vecto.transform(df_clean['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15819, 10000)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X=X.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y=df_clean[\"sentiment\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1    1\n",
       "2    2\n",
       "3    1\n",
       "4    1\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, shuffle=True,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6735     1\n",
       "13537    2\n",
       "6876     1\n",
       "10035    2\n",
       "5174     0\n",
       "        ..\n",
       "13418    1\n",
       "5390     1\n",
       "860      1\n",
       "15795    2\n",
       "7270     1\n",
       "Name: sentiment, Length: 12655, dtype: int64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting a simple model on training data and evaluate its performance\n",
    "\n",
    "Fit a model on your cleaned data. Use `train_vec` as your features. Note that you need to convert `train_vec` to an array. \n",
    "\n",
    "You are familiar with this process, so there is less guidance here. You may also refer to train notebooks and the webinar pdf as guidance.\n",
    "\n",
    "Your basic model should be a logistic regression, however if you try different models you will also perform the following procedure.\n",
    "\n",
    "1. Split the training data into features and labels.\n",
    "2. Split the training data further into training and validation data.\n",
    "3. Fit the model on the training subset. \n",
    "4. Predict on the validation subset.\n",
    "5. Calculate the performance metrics on the validation predictions.\n",
    "6. Select a model based on validation performance (when you have more than one model).\n",
    "8. Clean the test data.\n",
    "9. Predict on the cleaned test data.\n",
    "7. Write a csv that matches `sample_submission.csv`.\n",
    "8. Submit to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RIDGE CLASSIFIER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RidgeClassifier()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rclf_base=RidgeClassifier()\n",
    "Rclf_base.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6597153718039346"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Rcf1_pred= Rclf_base.predict(X_test)\n",
    "F1_Score=f1_score(y_test, Rcf1_pred, average=\"macro\")\n",
    "F1_Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=[1.0,1.5,2.0,2.5]\n",
    "solver=[\"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\", \"lbfgs\"]\n",
    "random_grid = {'alpha': alpha,\n",
    "               'solver': solver}\n",
    "                             \n",
    "print(random_grid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Rclf=RidgeClassifier()\n",
    "Rclf_random=RandomizedSearchCV(estimator = Rclf,\n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter =10, cv = 3,\n",
    "                                random_state=42)\n",
    "\n",
    "Rclf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rcf_pred= Rclf_random.predict(X_test)\n",
    "f1_score(y_test, Rcf_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#LOGISTIC REGRESSION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'multi_class': ['ovr'], 'C': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], 'solver': ['lbfgs', 'liblinear'], 'verbose': [1, 2, 3]}\n"
     ]
    }
   ],
   "source": [
    "MC= [\"ovr\"]\n",
    "C=[int(x) for x in range(2,15,1)]\n",
    "solver=[\"lbfgs\",\"liblinear\"]\n",
    "verbose=[1,2,3]\n",
    "# Create the randomgrid\n",
    "random_grid = {'multi_class': MC,\n",
    "               'C': C,\n",
    "               'solver': solver,\n",
    "               'verbose': verbose}\n",
    "                             \n",
    "print(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\Users\\JMOSOLA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\JMOSOLA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\JMOSOLA\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:814: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "[Parallel(n_jobs=1)]: Done   4 out of   4 | elapsed:   44.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomizedSearchCV(cv=3, error_score='raise', estimator=LogisticRegression(),\n",
       "                   n_jobs=-1,\n",
       "                   param_distributions={'C': [2, 3, 4, 5, 6, 7, 8, 9, 10, 11,\n",
       "                                              12, 13, 14],\n",
       "                                        'multi_class': ['ovr'],\n",
       "                                        'solver': ['lbfgs', 'liblinear'],\n",
       "                                        'verbose': [1, 2, 3]},\n",
       "                   random_state=42)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "rf_rc = LogisticRegression()\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf_rc,\n",
    "                                param_distributions = random_grid, \n",
    "                                n_iter =10, cv = 3,\n",
    "                                random_state=42, n_jobs = -1, error_score=\"raise\")\n",
    "\n",
    "rf_random.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_rc_pred= rf_random.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6651300891676323"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, lr_rc_pred, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'verbose': 1, 'solver': 'lbfgs', 'multi_class': 'ovr', 'C': 7}"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SVC BASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#SAVING MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "model_save_path = \"log_reg_model.pkl\"\n",
    "with open(model_save_path,'wb') as file:\n",
    "    pickle.dump(rf_random,file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_load_path = \"log_reg_model.pkl\"\n",
    "with open(model_load_path,'rb') as file:\n",
    "    unpickled_model = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=unpickled_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6651300891676323"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(y_test, pred_test, average=\"macro\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 127,   42,   96,   13],\n",
       "       [  13,  196,  194,   22],\n",
       "       [  14,  106, 1503,  132],\n",
       "       [   6,   20,  136,  544]], dtype=int64)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1:Pro</th>\n",
       "      <th>2:news</th>\n",
       "      <th>0:Neutral</th>\n",
       "      <th>-1:Anti</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1:Pro</th>\n",
       "      <td>127</td>\n",
       "      <td>42</td>\n",
       "      <td>96</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2:news</th>\n",
       "      <td>13</td>\n",
       "      <td>196</td>\n",
       "      <td>194</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0:Neutral</th>\n",
       "      <td>14</td>\n",
       "      <td>106</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>-1:Anti</th>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>136</td>\n",
       "      <td>544</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           1:Pro  2:news  0:Neutral  -1:Anti\n",
       "1:Pro        127      42         96       13\n",
       "2:news        13     196        194       22\n",
       "0:Neutral     14     106       1503      132\n",
       "-1:Anti        6      20        136      544"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels=[\"1:Pro\",\"2:news\",\"0:Neutral\",\"-1:Anti\"]\n",
    "pd.DataFrame(data=confusion_matrix(y_test, pred_test), index=labels, columns=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRANSFORM THE TEST DATA\n",
    "test=replace_urls(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Combine this with the polling of staffers re climate change and womens' rights and you have a fascist state. url-web\""
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.message[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[\"message\"]=test[\"message\"].apply(to_lowerd).apply(remove_stopword).apply(remove_punctuations).apply(tt_tokenized).apply(lemma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['combine',\n",
       " 'polling',\n",
       " 'staffer',\n",
       " 'climate',\n",
       " 'change',\n",
       " 'woman',\n",
       " 'right',\n",
       " 'fascist',\n",
       " 'state',\n",
       " 'urlweb']"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.message[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                  message  tweetid\n",
       "0      [europe, looking, china, make, sure, alone, fi...   169760\n",
       "1      [combine, polling, staffer, climate, change, w...    35326\n",
       "2      [scary, unimpeachable, evidence, climate, chan...   224985\n",
       "3      [karoli, morgfair, osborneink, dailykos, putin...   476263\n",
       "4      [rt, fakewillmoore, female, orgasm, cause, glo...   872928\n",
       "...                                                  ...      ...\n",
       "10541  [rt, brittanybohrer, brb, writing, poem, clima...   895714\n",
       "10542  [2016, year, climate, change, came, home, hott...   875167\n",
       "10543  [rt, loopvanuatu, pacific, country, positive, ...    78329\n",
       "10544  [rt, xanria, 00018, you, ’, re, hot, must, cau...   867455\n",
       "10545  [rt, chloebalaoing, climate, change, global, i...   470892\n",
       "\n",
       "[10546 rows x 2 columns]>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1=vecto.transform(test['message'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test1=X_test1.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_final=unpickled_model.predict(X_test1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_submit=pd.DataFrame(pred_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of        0\n",
       "0      1\n",
       "1      1\n",
       "2      1\n",
       "3      1\n",
       "4      0\n",
       "...   ..\n",
       "10541  1\n",
       "10542  1\n",
       "10543  1\n",
       "10544  0\n",
       "10545  1\n",
       "\n",
       "[10546 rows x 1 columns]>"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_submit.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_submit = test[['tweetid']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10541</th>\n",
       "      <td>895714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10542</th>\n",
       "      <td>875167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10543</th>\n",
       "      <td>78329</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>867455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10545</th>\n",
       "      <td>470892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10546 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       tweetid\n",
       "0       169760\n",
       "1        35326\n",
       "2       224985\n",
       "3       476263\n",
       "4       872928\n",
       "...        ...\n",
       "10541   895714\n",
       "10542   875167\n",
       "10543    78329\n",
       "10544   867455\n",
       "10545   470892\n",
       "\n",
       "[10546 rows x 1 columns]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids_submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweetid</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>169760</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>35326</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>224985</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>476263</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>872928</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tweetid  sentiment\n",
       "0   169760          1\n",
       "1    35326          1\n",
       "2   224985          1\n",
       "3   476263          1\n",
       "4   872928          0"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submit_all = pd.concat([ids_submit.reset_index(drop=True), pred_submit], axis=1).rename(columns = {0:'sentiment'})\n",
    "submit_all.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submit your best model predictions \n",
    "\n",
    "Don't forget to submit your the predictions on the best model to Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write csv for best predictions\n",
    "submit_all[['tweetid','sentiment']].to_csv('testsubmission.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
